/*
this program runs BALIMLE approach
It estimates all possible models.
*/

new; cls; rndseed 23;
library optmum;
#include optmum.ext;
begin=date;
prandom = 0;          @* prandom=1 for theta random Ley&Steel09. prandom = 0 for theta fixed *@
dilution = 0;
dil_power = 1/2;

@---------------------------------------------------------------------------------@
@		   	                     LOADING THE DATASET			        		  @
@---------------------------------------------------------------------------------@

row=292; column=11; t=4; n=73;
load rawdata[row,column]=.\data.csv;

@    VARIABLES IN RAWDATA                                                                 @
@    1.yt  2.yt1  3.ish  4.sed  5.pgrw  6.pop  7.ipr  8.opem  9.gsh  10.lnlex  11.polity  @
@-----------------------------------------------------------------------------------------@

rawdata=rawdata[.,1:6];   @ I select the regressors of interest @

let varlist[5,1] = "GDP" "ISH" "SED" "PGRW" "POP";

ktotx=cols(rawdata)-2; ktoty=ktotx+1;
{data,R}=transf1(rawdata);    @ this procedure transforms the data set:              @
                              @ first: standarization of variables                   @
                              @ second: cross-sectional de-mean (time dummies)       @
                              @ third: organization of data for the LIML estimation  @
                              @ variable data is cross-sectional demeaned data       @
@ dependent variable for the t periods NXt (matrix) @
Y1=zeros(n, t);
for i(0, t-1, 1);
    Y1[.,i+1]=R[.,2+ktoty*i];
endfor; 

@ predetermined variables for the t-1 periods @
Y2=zeros(n, ktotx*(t-1));
for j(0, t-2, 1);
    Y2[.,1+j*ktotx:(1+j)*ktotx]=R[.,3+(j+1)*ktoty:3+j+(j+2)*ktotx];
endfor;
X0=R[.,3:2+ktotx];
//X0 is for the first year, while Y2 for the 2:t//

corr_matrix=Corrx(data[.,3:2+ktotx]);



@---------------------------------------------------------------------------------@
@		               SOME PRELIMINAR OBJECTS BALIMLE APPROACH   			      @
@---------------------------------------------------------------------------------@

@***       PRIOR STRUCTURES for THE PRIOR MODEL SIZE                           ***@
@---------------------------------------------------------------------------------@

pmsize=ktotx/2;         @  prior expected model size, options:                    @
                     	@  1. for "SDM" priors pmsize=3	                          @
                     	@  2. for "FLS" priors pmsize=ktotx/2	                  @
pinc=pmsize/ktotx;
b=(ktotx-pmsize)/pmsize;      @ parameter for beta (random) distribution of the prior inclusion probability  @

@***                     STORAGE OBJECTS                                       ***@
@---------------------------------------------------------------------------------@

mod=zeros(ktoty,1); bet=zeros(ktoty,1); 
pvarh=zeros(ktoty,1); pvarr=zeros(ktoty,1);
fy=zeros(ktoty,1); fyt=0; ppmsize=0; cout=0;

@---------------------------------------------------------------------------------@
@		               LOOP COVERING FULL MODEL SPACE           			      @
@---------------------------------------------------------------------------------@

tot=2^ktotx;
@ total number of models to be estimated @
for turu(1, tot, 1);
    @rndseed 23;@
    
    mt=msel(turu);
    out = mt.== 0;          @ regressors out of the current model         @
    kx=sumc(mt); ky=kx+1;   @ number of regressors in the current model   @
    
    @ Z includes y0 and x0 as strictly exogenous variables @
    if kx==0; Z=R[.,1];
    else; X0j = (delif (X0',out))'; Z=R[.,1]~X0j;
    endif;
    
    @ Q is the model specific annihilator (or residual maker) matrix           @
    Q=eye(n)-Z*inv(Z'Z)*Z'; 
    @ nptbe is the Number of Parameters To Be Estimated in the current model  @
    nptbe = 2*ky+t+1+(t^2+t-2)*kx/2;  
    
    @ t0in is the vector of initial values for the likelihood optimization   @
    t0in=0.5*ones(nptbe,1);                                  
    
    @ we now call the optimization procedure for maximizing the likelihood function @
    optset; @optset resets all the global variables to their default values @ 
    cout1=0; opditer=100;
    _opstmth="steep one"; _opmdmth="bfgs brent"; @ we choose methods of optimisation and a step length 
    _opstmth is a starting method and _opmdmth is a middle method. When the number of iterations
    exceeds _opditer or when the function fails to change by _opdfct percent, the algorithm
    switches to _opmdmth.@
    
    @ predetermined variables for the t-1 periods @
    if kx!=0;
        cur_Y2=zeros(n,kx*(t-1));
        for j(0, t-2, 1);
            reg_ind=0;
            for reg_ch(1, ktotx, 1);
                if mt[reg_ch]==1;   @ if x variable is included @
                    reg_ind=reg_ind+1;
                    cur_Y2[., j*kx+reg_ind]=R[.,3+j+(j+1)*ktotx+reg_ch];
                endif;
            endfor;
        endfor;
    else;
        cur_Y2=0;
    endif;
    X0=R[.,3:2+ktotx];
    
    {theta,fout,grad,ret}=optmum(&lik,t0in); 
    @ theta returns optimized parameters, fout 
    is the value of the function lik at the maximum, grad is gradient vector at the minimum,
    and ret returns code from optmum (0 if successful) @ 
    
    @ we now compute model-specific standard errors @
    he=myhess(&lik,theta);
    likgra_value=likgra(theta);
    Gmat=gradp(&likgra,theta);
    Imat=Gmat'Gmat;
    stdr=sqrt(diag(inv(he)*(Imat)*inv(he)));
    stdh=sqrt(diag((inv(he))));
    varr=stdr.^2; varh=stdh.^2;
    
    @ storing results for the CURRENT model @
    df = 3 + t + 2*kx + kx * (t - 1) + kx * t * (t - 1)/2;
    logl=(-fout-(df/2)*(ln(n*t)))/n;
    bict=exp(logl);                              @ integrated likelihood approximation           @
    
    @ prior model probability (either random -Ley&Steel09- or fixed) @
    if prandom == 1;
        priorprobt=(gamma(1+kx))*(gamma(b+ktotx-kx));    @theta random@
    elseif prandom == 0;
        priorprobt=(pinc)^(kx)*(1-pinc)^(ktotx-kx);      @theta fixed@ 
    endif;
    
    if dilution == 1;
        x={};
        for i(1,ktotx,1);
            if mt[i]==1;
                x=x~i;
            endif;
        endfor;
        if cols(x)<=1;
            corr_det=1;
        else;
            cur_corr_matrix=corr_matrix[x,x];
            corr_det=det(cur_corr_matrix);
        endif;
        priorprobt=corr_det^dil_power*priorprobt;
    endif;

    @ posterior model probability  @
    postprob=priorprobt*bict;
    
    @ selecting estimates of interest (i.e. alpha and betas) @
    bt=theta[1:ky]; stdrt=stdr[1:ky]; stdht=stdh[1:ky];
    varht=varh[1:ky]; varrt=varr[1:ky];
    
    @ constructing the full vector of estimates @
    mty=1|mt; 
    bt1=zeros(ktoty,1);
    stdrt1=zeros(ktoty,1); stdht1=zeros(ktoty,1);
    varht1=zeros(ktoty,1); varrt1=zeros(ktoty,1);
    it1=0;
    it=1;
    for it(1,ktoty,1);
        if mty[it]==1;
            it1=1+it1;
            bt1[it]=bt[it1];
            stdrt1[it]=stdrt[it1];
            stdht1[it]=stdht[it1];
            varht1[it]=varht[it1];
            varrt1[it]=varrt[it1];
        else;
            bt1[it]=0;         @ if the regressor is not in the model, 0 @
            stdrt1[it]=0;
            stdht1[it]=0;
            varht1[it]=0;
            varrt1[it]=0;
        endif;
    endfor;
    
    @ calculating the percentage of significant regressions @
    ptr=bt1./stdht1;
    ntr=bt1./stdht1;
    if turu==1; pts=ptr; nts=ntr;
    else; pts=pts~ptr; nts=nts~ntr;
    endif;
        
    @ here I clear some global variables to save space in the memory @
    clear _eigerr,_rtl_ver,__weight,__vtype,__vpad,__tol,__sort,__rowfac,
    __row,__range,__prec,__output,__miss,__macheps,__INFp,__INFn,__INDEFp,__INDEFn,
    __fmtnv,__fmtcv,__ff,__con,__altnam;
    
    @ accumulating estimates for posterior model probabilities @
    mod=mod+mty;
    fy=fy+postprob*mty;
    fyt=fyt+postprob;
    ppmsize=ppmsize+postprob*(sumc(mty));
    
    @ storing estimates conditional on inclusion @
    bet=bet+postprob*bt1;   
    pvarr=pvarr+(postprob*varrt1+postprob*(bt1.*bt1));         @ as in Leamer (1978) @
    pvarh=pvarh+(postprob*varht1+postprob*(bt1.*bt1));         @ as in Leamer (1978) @
    
    @ here we store model-specific diagnostics and estimates (BICs, likelihoods, betas...) @   
    if turu==1;
        modprob=postprob; modelid=turu; modpri=priorprobt; liks=exp(-fout/n); bics=bict;
        betas=bt1; stds=stdht1; stdsr=stdrt1; foutt=-fout;
    else;
        modprob=modprob|postprob; modelid=modelid|turu; modpri=modpri|priorprobt; liks=liks|exp(-fout/n); bics=bics|bict;
        betas=betas~bt1; stds=stds~stdht1; stdsr=stdsr~stdrt1; foutt=foutt|(-fout);
    endif; 
    cls;
    
endfor;

@                         end of loop covering full model space                        @
@--------------------------------------------------------------------------------------@


popmsize=ppmsize/fyt;
modprob1=modprob/sumc(modprob);
idprob=modelid~modprob1~modpri~bics;

@ computing posterior moments CONDITIONAL on inclusion @
postprobinc=fy/fyt;
postmean=bet./fy;
varrleamer=(pvarr./fy)-postmean.^2;
varhleamer=(pvarh./fy)-postmean.^2;
poststdr=sqrt(varrleamer);
poststdh=sqrt(varhleamer);
tr=postmean./poststdr;
th=postmean./poststdh;

@ computing UNCONDITIONAL posterior moments  @
upostmean = postmean .* postprobinc;
uvarrleamer = (varrleamer + (postmean.^2)).*postprobinc - (upostmean.^2);
uvarhleamer = (varhleamer + (postmean.^2)).*postprobinc - (upostmean.^2);
upoststdr=sqrt(uvarrleamer);
upoststdh=sqrt(uvarhleamer);

@ computing percentage of significant coeff estimates @
nts=nts'; 
pts=pts';
for jt(1,ktoty,1);
    ntss=packr(nts[.,jt]); ptss=packr(pts[.,jt]); nsig=ntss.<-1.96; psig=ptss.>1.96;
        if jt==1; negper=meanc(nsig); posper=meanc(psig);
        else; negper=negper|meanc(nsig); posper=posper|meanc(psig);
        endif;
endfor;

@ we print final results in balimle_results.out file @
result=varlist~postprobinc~postmean~poststdh~poststdr~upostmean~upoststdh~upoststdr;
the_end=date; days=the_end[3]-begin[3]; et=(the_end[4]+8640000*days-begin[4])/100;

output file = balimle_results.out reset;
print;
print "varname -- postprob -- pmean -- std -- stdR -- unc_pmean -- unc_std -- unc_stdR";
let mask[1,8] = 0 1 1 1 1 1 1 1;
let fmt[8,3] = 
"-*.*s" 8 8 
"*.*lf" 10 4 
"*.*lf" 10 4 
"*.*lf" 10 4
"*.*lf" 10 4
"*.*lf" 10 4
"*.*lf" 10 4
"*.*lf" 10 4; 
d = printfm(result,mask,fmt);
print;
print " 1.- FURTHER INFORMATION ";
print "Prior Mean Model Size="; pmsize;
print "Prior Inclusion Probability="; pinc;
print "Posterior Mean Model Size="; popmsize;
print "minutes="; et/60;
print "hours="; (et/60)/60;
print "----------------------------------------------------------------------";
print;
print; " 2.- ALL BETAS (each row is a different model)";
print betas';
print;
print "----------------------------------------------------------------------";
print; " 3.- ALL STD. ERRORS (each row is a different model)";
print stds';
print;
print "----------------------------------------------------------------------";
print; " 4.- ALL ROBUST STD. ERRORS (each row is a different model)";
print stdsr';
print;
print "----------------------------------------------------------------------";
print;
print " 5.- MODELS INFO ";
print " model -- postprob -- priorprob -- bics";
print idprob;
output off;

#include ./liks1R.gss;
#include ./oprocsR.gss;
#include ./optimsR.gss;
